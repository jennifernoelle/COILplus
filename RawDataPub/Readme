The raw data folder includes new interactions from the recent publication, 
excluding interactions that were not given at the species level for animals or plants, 
were not associated with a study. 

- frug_data_total2.csv: frugivory interactions with study ID, study site, country, zone, focus
  - Study_ID starts with CD if it's from Camille's collection, DB if it's from the new paper
  - Animal and plant taxa type are more coarse groupings than family
- frigovpre_trait.csv
- plant_trait.csv

- Same site, different study
- Same country, diff everything else
- Same region

Trait cleaning: 
- Plants: we had 107 observations missing fruit width, 94 missing fruit length, 2 missing wood desnsity. 
  Where only fruit length is available, we impute width = length/ mean(length:width) if possible, 
  if not, then we use genus, family means. Genus and family means are used for wood density. 
- Verts: two species were missing generation length, we impute using genus and family means. 
Phylogenies: bird and mammal trees from VertLife

Focus considerations: 
- Animal (7618)
- Plant (817)
- Both (1639) - network studies, all interactions are recorded
- BothLimited (268) focuses on a limited number of plant and a limited number of animal species - in this case only interactions have Focus ==1
 because a chimp eating a mango could mean either mango or chimp or both was focal, conservative assumption. 
 
 By study: 
 > table(methods$method) # this version created new study IDs for different locations

     Animal        Both BothLimited       Plant     Unknown 
        256           3          39          22           7 
        
> table(frug_studies$focus)
        Animal        Both BothLimited       Plant 
        221           3          27          16 
        

- Consider running separate versions for birds, mammals, elephants, apes, mokeys, ungulates, bats, carnivores
- EDA: look at relationship between traits within groups, phylogeny
- Think about definining different default probs for birds and mammals
- We might have range maps for birds and mammals to use for occurrence indicators but this will be more work, shape files etc

- For camille's paper: add more text to the supplementary materials section on methods, add robustness checks, reviewers were skeptical

FILES in raw data
- study_info1.dat - 
- study_info2.dat


RUNNING TO DO LIST
- Reproduce trace plots for pd_B4 for Camille's paper - for some reason those didn't save 
- X Look at trace plots from longest runs
  - Note we need to rerun pd_C4 but we can at least set up the plots without
- Look at posterior occurrence probabilities: argue using p75 results in unlikely occurrences and so we shouldn't trust results
- Look at trace plots from the long runs where we have them
- Investigate failure of longer runs and consider restarting with minimal saved results
- x Add 400 sample runs blocked/unblocked scenarios which were previously the same due to a typo (I think it was only unblocked running before)
- X Give camille data table and recs: plot heatmaps, look at mean p_holdout
- X Rerun saving occurrence indicators (full data) except for BC which need to be fixed
- X Fix unblocked vs blocked cv
- Create one version that saves more rho samples
- X Fix imputation: we get negative numbers where that doesn't make sense
- X Rerun sampler with corrected code or maybe just log transform?
- X Rework trait matching code
- X Debug plotting and analysis of occurence probs: why are we sampling when occurrence is known?
- X Double check combining the chains code, indices seem wrong
- X Investigate NA's in median ratio
- X Subset heatmap with Camille's species list and make plots
- Trait matching: add new metric plots and heatmap plots
- X Add failed CV runs
- X Run longer with stored burn-in: trace_plots look good they're just so zoomed in because of long burn
- X CV subset to Gabon species

FROM CAMILLE: 
- Map of sites



SCENARIOS

To-do before running 
- x check expert scenario
- x make sure number of cv holdouts makes sense
- x Update full code (not cv) to return data necessary for trait matching
- x Update full code to save occurrence probs for animals too
- x Update full code to save p_OP_mean, currently saving an old null object
- x Restart simulations with updated traits data (old cv numbers are probably still close)

- x Time it: approx 1000 iterations/20 hours -> 50 iter/hour -> 1200 per day
  Total iterations = thin*Nsims + 5*thin*Nsims (will be longer if sampling occurrence probs though)
  - 20sims - 1200 total :Nsims, thin, burn = (20, 10, 1000) 
  - 100sims - 6000: Nsims, thin, burn = (100, 10, 5000): 5 days
  - 200sims - 12000: (200,10, 10000): 10 days
  - 400sims - 24000: (400, 10, 20000): 20 days
  
Analyzing results: for each scenario (max number of samples only)
- x Setup ifelse statements to use the right value of sampleP, O_P, O_V depending on the context
- x Update S400 CV results for blocked sampler previously not run due to type
- x Restart mistaken p75_C4 res run where i accidentally ran C3 (200 samples only) so we don't have occurrence indicators for S400
- Rerun S400 saving only rho's and not thinning, no burn-in to get better trace plots?
  - First do short test run of new MCMC code to make sure it works
  - Run for pd_B4, pd_C4 with S400 using old settings
  - Also try running with new cluster settings suggested by Luca to see if it's faster
- Save cv plotting data for all models to compare from S400 for plots & create combined plots
- Pull traceplots from the largest completed models run
- Save occurrence indicator data for all models - possibly using whichever runs didn't fail for S2000 & create combined plots
  - Decide which models we want to compare which things for
    - p0_A: p = 0/1 so we do not update occurrence indicators, all will be unchanged
    - p75_A,B,C: p = 0.75/1 so we update occurrence indictors, compare occurrence indicators between all three samplers 
    - pd_A,B,C: p in (0, 0.25, ...) so we update occurrence indicators and can ompare between all three samplers
    - p75_B,C & pd_B,C: we can also compare occurrence probabilities but they are of secondary interest
  - Decide what kind of occurrence plots we want and save the data needed to make those plots
- Run trait matching


Run each of these on the full data and cross validation for nSims, burn, thin: ()
We're only recording the 100, 200, 400 samples versions (20 only for prelim results sanity checking)

A,B,C refers to sampler, 1:4 refers to sims

Quandaries:
- Why is Expert giving such high post probs, especially as we move from 200 to 400 samples?
- X Why is median 0?
  Post probability is computed across MCMC samples, of which there are only 1600, so for
  very low probs, the number of 1's might be below precision limits in R
  Note that the two lowest values are 0, 1/1600 = 0.00625
- X Check to see if median prob is actually 0? Is this saved too? It's a v low but nonzero number
- X Why do analysis files for blocked vs unblocked code yield different results but CV the same? Typo 
- X Decide if we need to run p0 with new methods - no

_ p0_old - A1:4 - CV runs started 6/10
 _ 20 res
 _ 100 res 
 xx 200 res cv
 xx 400 res cv restarted 8/23
  _ 400 res started 10/4 saving occ indicators


ip p75_old - A1:4 
 xx  20 res, cv
 xx 100 res, cv. maybe added?
 xx 200 res, cv
 xx 400 res, cv (failure in core 8 of CV restarted) restarted 8/23
  _ 400 res started 10/4 saving occ indicators
 
 
ip p75_nb - B1:4
  _ 20 res NO CV
 x 100 res, cv
 xx 200 res, cv
 x_ 400 res, cv restarted 10/4 due to typo
  _ 400 res started 10/4 saving occ indicators

ip p75_b - C1:4
 x 20 res, cv
 x 100 res, cv
 xx 200 res, cv
 xx 400 res  cv restarted 10/4 due to typo
 _ 400 res started 12/4 saving occ indicators due to restarting s200 accidentally on 10/4
 
_ pexpert_old 
_ pexpert_p_nb
_ pexpert_p_b

x pdefault_old A1:4 
 x 20 res, cv
 x 100 res, cv
 xx 200 res, cv 
 x_ 400 res, cv failed for one replicate, restarted 8/23
  _ 400 res started 10/4 saving occ indicators
 
ip pdefault_p_nb B1:4
 x 20 res, cv
 x 100 res, cv
 xx 200 res, cv
 x_ 400 res, cv, restarted 10/4 due to typo
 
ip pdefault_p_b C1:4
 x 20 res, cv
 x 100 res, cv
 xx 200 res, cv
 x_ 400 res, cv, restarted 10/4 due to typo


### EXTRA LONG RUNS FOR MANUSCRIPT MIXING: how long?
 Total iterations = thin*Nsims + 5*thin*Nsims (will be longer if sampling occurrence probs though)
 approx 1000 iterations/20 hours -> 50 iter/hour -> 1200 per day
 
  - 20sims - 1200 total :Nsims, thin, burn = (20, 10, 1000) 
  - 100sims - 6000: Nsims, thin, burn = (100, 10, 5000): 5 days
  - 200sims - 12000: (200,10, 10000): 10 days
  - 400sims - 24000: (400, 10, 20000): 20 days
  - 1200sims - 22000: (1200, 10, 10000): 18 days
  - 2000sims - 30000: (2000, 10, 10000): 25 days
  - 5000sims - 60000: (5000, 10, 10000): 50 days
  
pdefault 
  A5:6 2000 5000
  B5:6 2000 5000
  C5:6 2000 5000
p75 
  A5:6 2000 5000
  B5:6 2000 5000
  C5:6 2000 5000 

